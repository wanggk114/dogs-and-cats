{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras_merge_3_app\n",
    "整体说明：\n",
    "- 1、使用keras的Xception、ResNet50、InceptonResNetV2预训练模型分别提取特征向量\n",
    "- 2、整合3个模型的特征向量\n",
    "- 3、构建一个简单模型，进行训练、预测\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "数据目录结构：\n",
    "data/\n",
    "    train/    #原始数据，train.zip解压后生成\n",
    "        dog.0.jpg\n",
    "        cat.0.jpg\n",
    "        ...\n",
    "    train2/   #按标签分目录后的数据（连接文件）\n",
    "        dog/\n",
    "            dog.0.jpg\n",
    "            dog.1.jpg\n",
    "            ...\n",
    "        cat/\n",
    "            cat.0.jpg\n",
    "            cat.1.jpg\n",
    "            ...\n",
    "    train3/   #去除异常图片后的训练数据（连接文件）\n",
    "        dog/    #9983张图片\n",
    "            dog.0.jpg\n",
    "            dog.1.jpg\n",
    "            ...\n",
    "        cat/    #9961张图片\n",
    "            cat.0.jpg\n",
    "            cat.1.jpg\n",
    "            ...\n",
    "    validation/  #去除异常图片后的验证数据（连接文件）\n",
    "        dog/   #2496张图片\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cat/   #2490张图片\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "    test/     \n",
    "        test/  #测试集数据，12500张图片\n",
    "            1.jpg\n",
    "            2.jpg\n",
    "            ...\n",
    "'''\n",
    "import cv2\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm   #进度条\n",
    "from PIL import Image\n",
    "from helper import *\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils import *\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "train_data_dir = 'data/train2'\n",
    "test_data_dir='data/test'\n",
    "\n",
    "\n",
    "batch_size = 72   #19944/72=277  4986/72=69.25\n",
    "epochs=20\n",
    "VER=1\n",
    "#模型权重文件\n",
    "model_h5file_base=\"Merge-tuning-v{}.h5\".format(VER)\n",
    "\n",
    "#预测结果文件\n",
    "pred_file_base=\"pred-Merge-tuning-v{}.csv\".format(VER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存特征向量\n",
    "def write_feature_data(MODEL, image_shape, weights_file, batch_size, preprocess_input = None):\n",
    "    input_tensor = Input((image_shape[0], image_shape[1], 3))\n",
    "    x = input_tensor\n",
    "    if preprocess_input:\n",
    "        x = Lambda(preprocess_input)(x)\n",
    "    \n",
    "    base_model = MODEL(input_tensor=x, weights='None', include_top=False) \n",
    "    base_model.load_weights(weights_file)  #用自己训练的权重文件\n",
    "    \n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "    gen = ImageDataGenerator()\n",
    "    train_generator = gen.flow_from_directory(train_data_dir, image_shape, shuffle=False, \n",
    "                                              batch_size=batch_size)\n",
    "    test_generator = gen.flow_from_directory(test_data_dir, image_shape, shuffle=False, \n",
    "                                             batch_size=batch_size, class_mode=None)\n",
    "    print(train_generator.samples)\n",
    "    print(test_generator.samples)\n",
    "    \n",
    "    train_feature = model.predict_generator(train_generator, train_generator.samples, verbose=1)\n",
    "    test_feature = model.predict_generator(test_generator, test_generator.samples, verbose=1)\n",
    "    \n",
    "    with h5py.File(\"feature_%s.h5\"%base_model.name) as h:\n",
    "        h.create_dataset(\"train\", data=train_feature)\n",
    "        h.create_dataset(\"test\", data=test_feature)\n",
    "        h.create_dataset(\"label\", data=train_generator.classes)\n",
    "        \n",
    "#用三个模型fine-tuning时，预测结果最好的权重文件提取特征向量\n",
    "write_feature_data(ResNet50, (224, 224), \"ResNet50-fine-tuning-3-v1.h5\", batch_size=batch_size, resnet50.preprocess_input)\n",
    "write_feature_data(Xception, (299, 299), \"xception-fine-tuning-1.h5\", batch_size=batch_size, xception.preprocess_input)\n",
    "write_feature_data(InceptionResNetV2, (299, 299), \"InceptonResNetV2-fine-tuning-2-v2.h5\", batch_size=batch_size, inception_resnet_v2.preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#从文件中读取特征向量和标签\n",
    "\n",
    "np.random.seed(2018)\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "for filename in [\"feature_ResNet50.h5\", \"feature_Xception.h5\", \"feature_InceptionResNetV2.h5\"]:\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        X_train.append(np.array(h['train']))\n",
    "        X_test.append(np.array(h['test']))\n",
    "        y_train = np.array(h['label'])\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=1)\n",
    "X_test = np.concatenate(X_test, axis=1)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构造模型\n",
    "start = time.clock()\n",
    "\n",
    "input_tensor = Input(X_train.shape[1:])\n",
    "\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "model = Model(input_tensor, x)\n",
    "\n",
    "#adam = optimizers.Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "#model.compile(optimizer=adam,\n",
    "model.compile(optimizer='adadelta',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "print(\"Load base model used time:\", (time.clock() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练模型并保存在验证集上损失函数最小的权重\n",
    "checkpoint = ModelCheckpoint(model_h5file_base, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min') #如发现loss相比上一个epoch训练没有下降,则经过3个epoch后停止训练\n",
    "callbacks_list = [stopping,checkpoint]\n",
    "\n",
    "history=model.fit(X_train, Y_train, batch_size=128, epochs=epochs, validation_split=0.2, shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可视化学习曲线\n",
    "show_learning_curve(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#预测结果   \n",
    "predict_on_model(X_test, model, model_h5file_base, pred_file_base)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
