{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras_merge_3_app\n",
    "整体说明：\n",
    "- 1、使用keras的Xception、ResNet50、InceptonResNetV2预训练模型分别提取特征向量\n",
    "- 2、整合3个模型的特征向量\n",
    "- 3、构建一个简单模型，进行训练、预测\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "数据目录结构：\n",
    "data/\n",
    "    train/    #原始数据，train.zip解压后生成\n",
    "        dog.0.jpg\n",
    "        cat.0.jpg\n",
    "        ...\n",
    "    train2/   #按标签分目录后的数据（连接文件）\n",
    "        dog/\n",
    "            dog.0.jpg\n",
    "            dog.1.jpg\n",
    "            ...\n",
    "        cat/\n",
    "            cat.0.jpg\n",
    "            cat.1.jpg\n",
    "            ...\n",
    "    train3/   #去除异常图片后的训练数据（连接文件）\n",
    "        dog/    #9983张图片\n",
    "            dog.0.jpg\n",
    "            dog.1.jpg\n",
    "            ...\n",
    "        cat/    #9961张图片\n",
    "            cat.0.jpg\n",
    "            cat.1.jpg\n",
    "            ...\n",
    "    validation/  #去除异常图片后的验证数据（连接文件）\n",
    "        dog/   #2496张图片\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cat/   #2490张图片\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "    test/     \n",
    "        test/  #测试集数据，12500张图片\n",
    "            1.jpg\n",
    "            2.jpg\n",
    "            ...\n",
    "'''\n",
    "import cv2\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm   #进度条\n",
    "from PIL import Image\n",
    "from helper import *\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils import *\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "train_data_dir = 'data/train2'\n",
    "test_data_dir='data/test'\n",
    "\n",
    "\n",
    "epochs=200\n",
    "VER=1\n",
    "#模型权重文件\n",
    "model_h5file_base=\"Merge-tuning-v{}.h5\".format(VER)\n",
    "model_h5file_base2=\"Merge-tuning-2-v{}.h5\".format(VER)\n",
    "\n",
    "#预测结果文件\n",
    "pred_file_base=\"pred-Merge-tuning-v{}.csv\".format(VER)\n",
    "pred_file_base2=\"pred-Merge-tuning-2-v{}.csv\".format(VER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24930 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "277/277 [==============================] - 252s 911ms/step\n",
      "100/100 [==============================] - 124s 1s/step\n",
      "get ResNet50 freature over!\n",
      "Found 24930 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "277/277 [==============================] - 597s 2s/step\n",
      "100/100 [==============================] - 301s 3s/step\n",
      "get Xception freature over!\n",
      "Found 24930 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "277/277 [==============================] - 721s 3s/step\n",
      "100/100 [==============================] - 354s 4s/step\n",
      "get InceptionResNetV2 freature over!\n"
     ]
    }
   ],
   "source": [
    "#保存特征向量\n",
    "def write_feature_data(MODEL, image_shape, weights_file, preprocess_input = None):\n",
    "    input_tensor = Input((image_shape[0], image_shape[1], 3))\n",
    "    x = input_tensor\n",
    "    if preprocess_input:\n",
    "        x = Lambda(preprocess_input)(x)\n",
    "    \n",
    "    base_model = MODEL(input_tensor=x, weights=weights_file, include_top=False) \n",
    "    \n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "    gen = ImageDataGenerator()\n",
    "    train_generator = gen.flow_from_directory(train_data_dir, image_shape, shuffle=False, \n",
    "                                              batch_size=90)\n",
    "    test_generator = gen.flow_from_directory(test_data_dir, image_shape, shuffle=False, \n",
    "                                             batch_size=125, class_mode=None)\n",
    "    \n",
    "    train_feature = model.predict_generator(train_generator, train_generator.samples//90, verbose=1)\n",
    "    test_feature = model.predict_generator(test_generator, test_generator.samples//125, verbose=1)\n",
    "    \n",
    "    with h5py.File(\"feature_%s.h5\"%base_model.name) as h:\n",
    "        h.create_dataset(\"train\", data=train_feature)\n",
    "        h.create_dataset(\"test\", data=test_feature)\n",
    "        h.create_dataset(\"label\", data=train_generator.classes)\n",
    "\n",
    "        \n",
    "#用三个模型在imagenet上的预训练权重文件提取特征向量\n",
    "write_feature_data(ResNet50, (224, 224), 'imagenet',  preprocess_input = resnet50.preprocess_input)\n",
    "print(\"get ResNet50 freature over!\")\n",
    "write_feature_data(Xception, (299, 299), 'imagenet',  preprocess_input = xception.preprocess_input)\n",
    "print(\"get Xception freature over!\")\n",
    "write_feature_data(InceptionResNetV2, (299, 299), 'imagenet',  preprocess_input = inception_resnet_v2.preprocess_input)\n",
    "print(\"get InceptionResNetV2 freature over!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#从文件中读取特征向量和标签\n",
    "\n",
    "np.random.seed(2018)\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "for filename in [\"feature_resnet50.h5\", \"feature_xception.h5\", \"feature_inception_resnet_v2.h5\"]:\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        X_train.append(np.array(h['train']))\n",
    "        X_test.append(np.array(h['test']))\n",
    "        y_train = np.array(h['label'])\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=1)\n",
    "X_test = np.concatenate(X_test, axis=1)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构造模型\n",
    "\n",
    "input_tensor = Input(X_train.shape[1:])\n",
    "\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "model = Model(input_tensor, x)\n",
    "\n",
    "model.compile(optimizer='adadelta',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19944 samples, validate on 4986 samples\n",
      "Epoch 1/200\n",
      "19944/19944 [==============================] - 5s 251us/step - loss: 0.0693 - acc: 0.9792 - val_loss: 0.0214 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02142, saving model to Merge-tuning-v1.h5\n",
      "Epoch 2/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0202 - acc: 0.9954 - val_loss: 0.0214 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02142 to 0.02139, saving model to Merge-tuning-v1.h5\n",
      "Epoch 3/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0171 - acc: 0.9964 - val_loss: 0.0180 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02139 to 0.01804, saving model to Merge-tuning-v1.h5\n",
      "Epoch 4/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0152 - acc: 0.9965 - val_loss: 0.0174 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01804 to 0.01737, saving model to Merge-tuning-v1.h5\n",
      "Epoch 5/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0149 - acc: 0.9963 - val_loss: 0.0166 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01737 to 0.01657, saving model to Merge-tuning-v1.h5\n",
      "Epoch 6/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0144 - acc: 0.9970 - val_loss: 0.0163 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01657 to 0.01628, saving model to Merge-tuning-v1.h5\n",
      "Epoch 7/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0147 - acc: 0.9968 - val_loss: 0.0164 - val_acc: 0.9968\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.01628\n",
      "Epoch 8/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0137 - acc: 0.9969 - val_loss: 0.0192 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.01628\n",
      "Epoch 9/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0133 - acc: 0.9975 - val_loss: 0.0226 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01628\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "#训练模型并保存在验证集上损失函数最小的权重\n",
    "checkpoint = ModelCheckpoint(model_h5file_base, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min') #如连续3个epoch,loss都没有没有下降,则停止训练\n",
    "callbacks_list = [stopping,checkpoint]\n",
    "\n",
    "history=model.fit(X_train, y_train, batch_size=128, epochs=epochs, validation_split=0.2, shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#可视化学习曲线\n",
    "show_learning_curve(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 1s 54us/step\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/dogs-and-cats/helper.py:169: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(index-1, 'label', y_test[i])\n"
     ]
    }
   ],
   "source": [
    "#预测结果   \n",
    "predict_on_model2(X_test,test_data_dir, 125, model, model_h5file_base, pred_file_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 换个优化算法 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构造模型\n",
    "\n",
    "input_tensor = Input(X_train.shape[1:])\n",
    "\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "model2 = Model(input_tensor, x)\n",
    "\n",
    "        adam = optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False) #训练快,把lr设置小一点\n",
    "model2.compile(optimizer=adam,\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19944 samples, validate on 4986 samples\n",
      "Epoch 1/200\n",
      "19944/19944 [==============================] - 5s 254us/step - loss: 0.9020 - acc: 0.4125 - val_loss: 0.7027 - val_acc: 0.5323\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.70269, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 2/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.6604 - acc: 0.6241 - val_loss: 0.5077 - val_acc: 0.8389\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.70269 to 0.50766, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 3/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.4931 - acc: 0.7808 - val_loss: 0.3789 - val_acc: 0.9394\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.50766 to 0.37887, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 4/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.3857 - acc: 0.8717 - val_loss: 0.2920 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.37887 to 0.29201, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 5/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.3061 - acc: 0.9226 - val_loss: 0.2327 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.29201 to 0.23271, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 6/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.2495 - acc: 0.9486 - val_loss: 0.1908 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.23271 to 0.19080, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 7/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.2119 - acc: 0.9588 - val_loss: 0.1600 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.19080 to 0.15998, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 8/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.1780 - acc: 0.9708 - val_loss: 0.1372 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.15998 to 0.13715, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 9/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.1564 - acc: 0.9733 - val_loss: 0.1194 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.13715 to 0.11935, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 10/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.1367 - acc: 0.9797 - val_loss: 0.1053 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.11935 to 0.10534, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 11/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.1222 - acc: 0.9812 - val_loss: 0.0941 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.10534 to 0.09411, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 12/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.1103 - acc: 0.9838 - val_loss: 0.0848 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.09411 to 0.08481, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 13/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.1007 - acc: 0.9840 - val_loss: 0.0771 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.08481 to 0.07712, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 14/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0917 - acc: 0.9858 - val_loss: 0.0706 - val_acc: 0.9916\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.07712 to 0.07064, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 15/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0831 - acc: 0.9871 - val_loss: 0.0651 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.07064 to 0.06513, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 16/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0774 - acc: 0.9878 - val_loss: 0.0604 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.06513 to 0.06039, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 17/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0722 - acc: 0.9884 - val_loss: 0.0562 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.06039 to 0.05624, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 18/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0682 - acc: 0.9893 - val_loss: 0.0526 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.05624 to 0.05263, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 19/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0635 - acc: 0.9891 - val_loss: 0.0495 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.05263 to 0.04949, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 20/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0589 - acc: 0.9899 - val_loss: 0.0467 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.04949 to 0.04668, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 21/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0550 - acc: 0.9907 - val_loss: 0.0442 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.04668 to 0.04419, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 22/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0529 - acc: 0.9907 - val_loss: 0.0420 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.04419 to 0.04199, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 23/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0499 - acc: 0.9910 - val_loss: 0.0400 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.04199 to 0.03999, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 24/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0479 - acc: 0.9920 - val_loss: 0.0382 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.03999 to 0.03819, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 25/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0455 - acc: 0.9923 - val_loss: 0.0366 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.03819 to 0.03658, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 26/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0443 - acc: 0.9917 - val_loss: 0.0351 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.03658 to 0.03511, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 27/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0414 - acc: 0.9924 - val_loss: 0.0338 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.03511 to 0.03377, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 28/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0402 - acc: 0.9923 - val_loss: 0.0326 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.03377 to 0.03256, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 29/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0388 - acc: 0.9931 - val_loss: 0.0315 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.03256 to 0.03146, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 30/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0376 - acc: 0.9928 - val_loss: 0.0304 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.03146 to 0.03043, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 31/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0356 - acc: 0.9932 - val_loss: 0.0295 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.03043 to 0.02952, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 32/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0340 - acc: 0.9937 - val_loss: 0.0287 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.02952 to 0.02866, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 33/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0339 - acc: 0.9931 - val_loss: 0.0279 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.02866 to 0.02787, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 34/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0323 - acc: 0.9941 - val_loss: 0.0271 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.02787 to 0.02714, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 35/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0320 - acc: 0.9938 - val_loss: 0.0265 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.02714 to 0.02648, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 36/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0311 - acc: 0.9939 - val_loss: 0.0259 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.02648 to 0.02586, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 37/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0299 - acc: 0.9944 - val_loss: 0.0253 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.02586 to 0.02529, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 38/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0284 - acc: 0.9940 - val_loss: 0.0248 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.02529 to 0.02476, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 39/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0292 - acc: 0.9941 - val_loss: 0.0243 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.02476 to 0.02429, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 40/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0281 - acc: 0.9942 - val_loss: 0.0238 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.02429 to 0.02384, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 41/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0274 - acc: 0.9945 - val_loss: 0.0234 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.02384 to 0.02344, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 42/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0262 - acc: 0.9945 - val_loss: 0.0230 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.02344 to 0.02303, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 43/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0252 - acc: 0.9952 - val_loss: 0.0227 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.02303 to 0.02267, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 44/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0254 - acc: 0.9949 - val_loss: 0.0223 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.02267 to 0.02235, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 45/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0253 - acc: 0.9942 - val_loss: 0.0220 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.02235 to 0.02203, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 46/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0243 - acc: 0.9948 - val_loss: 0.0217 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.02203 to 0.02175, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 47/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0241 - acc: 0.9950 - val_loss: 0.0215 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.02175 to 0.02148, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 48/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0240 - acc: 0.9949 - val_loss: 0.0212 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.02148 to 0.02124, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 49/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0234 - acc: 0.9954 - val_loss: 0.0210 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.02124 to 0.02101, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 50/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0238 - acc: 0.9946 - val_loss: 0.0208 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.02101 to 0.02084, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 51/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0222 - acc: 0.9956 - val_loss: 0.0206 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.02084 to 0.02059, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 52/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0219 - acc: 0.9949 - val_loss: 0.0204 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.02059 to 0.02042, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 53/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0227 - acc: 0.9948 - val_loss: 0.0202 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.02042 to 0.02024, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 54/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0213 - acc: 0.9958 - val_loss: 0.0201 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.02024 to 0.02007, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 55/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0215 - acc: 0.9953 - val_loss: 0.0199 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.02007 to 0.01990, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 56/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0215 - acc: 0.9954 - val_loss: 0.0198 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.01990 to 0.01977, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 57/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0206 - acc: 0.9957 - val_loss: 0.0196 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.01977 to 0.01964, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 58/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0201 - acc: 0.9956 - val_loss: 0.0195 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.01964 to 0.01951, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 59/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0206 - acc: 0.9951 - val_loss: 0.0194 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.01951 to 0.01937, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 60/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0207 - acc: 0.9953 - val_loss: 0.0193 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.01937 to 0.01927, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 61/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0202 - acc: 0.9956 - val_loss: 0.0191 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.01927 to 0.01915, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 62/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0206 - acc: 0.9954 - val_loss: 0.0190 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.01915 to 0.01904, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 63/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0199 - acc: 0.9953 - val_loss: 0.0190 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.01904 to 0.01896, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 64/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0195 - acc: 0.9961 - val_loss: 0.0189 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.01896 to 0.01892, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 65/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0191 - acc: 0.9956 - val_loss: 0.0188 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.01892 to 0.01879, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 66/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0195 - acc: 0.9959 - val_loss: 0.0187 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.01879 to 0.01870, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 67/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0192 - acc: 0.9961 - val_loss: 0.0186 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.01870 to 0.01864, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 68/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0198 - acc: 0.9955 - val_loss: 0.0186 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.01864 to 0.01856, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 69/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0192 - acc: 0.9957 - val_loss: 0.0185 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.01856 to 0.01850, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 70/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0187 - acc: 0.9962 - val_loss: 0.0185 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.01850 to 0.01846, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 71/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0184 - acc: 0.9964 - val_loss: 0.0184 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.01846 to 0.01836, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 72/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0193 - acc: 0.9958 - val_loss: 0.0183 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.01836 to 0.01829, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 73/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0181 - acc: 0.9962 - val_loss: 0.0183 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.01829 to 0.01827, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 74/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0182 - acc: 0.9957 - val_loss: 0.0182 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.01827 to 0.01820, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 75/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0192 - acc: 0.9956 - val_loss: 0.0182 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.01820 to 0.01815, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 76/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0175 - acc: 0.9961 - val_loss: 0.0181 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.01815 to 0.01812, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 77/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0182 - acc: 0.9962 - val_loss: 0.0180 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.01812 to 0.01804, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 78/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0179 - acc: 0.9965 - val_loss: 0.0180 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.01804 to 0.01800, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 79/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0177 - acc: 0.9960 - val_loss: 0.0180 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.01800 to 0.01795, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 80/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0181 - acc: 0.9957 - val_loss: 0.0180 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.01795\n",
      "Epoch 81/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0176 - acc: 0.9957 - val_loss: 0.0179 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.01795 to 0.01790, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 82/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0169 - acc: 0.9964 - val_loss: 0.0179 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.01790 to 0.01785, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 83/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0177 - acc: 0.9961 - val_loss: 0.0178 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.01785 to 0.01781, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 84/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0180 - acc: 0.9963 - val_loss: 0.0178 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.01781 to 0.01777, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 85/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0173 - acc: 0.9962 - val_loss: 0.0178 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.01777 to 0.01775, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 86/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0168 - acc: 0.9961 - val_loss: 0.0177 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.01775 to 0.01771, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 87/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0171 - acc: 0.9965 - val_loss: 0.0177 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.01771 to 0.01770, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 88/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0169 - acc: 0.9965 - val_loss: 0.0177 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.01770 to 0.01765, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 89/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0165 - acc: 0.9965 - val_loss: 0.0176 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.01765 to 0.01763, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 90/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0169 - acc: 0.9963 - val_loss: 0.0176 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.01763 to 0.01759, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 91/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0173 - acc: 0.9964 - val_loss: 0.0176 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.01759 to 0.01757, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 92/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0174 - acc: 0.9960 - val_loss: 0.0176 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.01757 to 0.01757, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 93/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0168 - acc: 0.9963 - val_loss: 0.0175 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.01757 to 0.01751, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 94/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0162 - acc: 0.9966 - val_loss: 0.0175 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.01751 to 0.01747, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 95/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0175 - acc: 0.9962 - val_loss: 0.0175 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.01747 to 0.01746, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 96/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0167 - acc: 0.9966 - val_loss: 0.0174 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.01746 to 0.01744, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 97/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0174 - acc: 0.9962 - val_loss: 0.0174 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.01744 to 0.01742, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 98/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0166 - acc: 0.9961 - val_loss: 0.0174 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.01742\n",
      "Epoch 99/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0170 - acc: 0.9962 - val_loss: 0.0174 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.01742 to 0.01738, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 100/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0164 - acc: 0.9965 - val_loss: 0.0174 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.01738 to 0.01737, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 101/200\n",
      "19944/19944 [==============================] - 1s 48us/step - loss: 0.0163 - acc: 0.9968 - val_loss: 0.0173 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.01737 to 0.01735, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 102/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0163 - acc: 0.9965 - val_loss: 0.0173 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.01735 to 0.01734, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 103/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0164 - acc: 0.9960 - val_loss: 0.0173 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.01734\n",
      "Epoch 104/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0160 - acc: 0.9964 - val_loss: 0.0173 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.01734 to 0.01730, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 105/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0165 - acc: 0.9966 - val_loss: 0.0173 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.01730 to 0.01727, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 106/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0158 - acc: 0.9963 - val_loss: 0.0173 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.01727 to 0.01725, saving model to Merge-tuning-2-v1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0163 - acc: 0.9965 - val_loss: 0.0173 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.01725\n",
      "Epoch 108/200\n",
      "19944/19944 [==============================] - 1s 53us/step - loss: 0.0153 - acc: 0.9969 - val_loss: 0.0172 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.01725 to 0.01723, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 109/200\n",
      "19944/19944 [==============================] - 1s 54us/step - loss: 0.0152 - acc: 0.9967 - val_loss: 0.0172 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.01723 to 0.01721, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 110/200\n",
      "19944/19944 [==============================] - 1s 52us/step - loss: 0.0162 - acc: 0.9965 - val_loss: 0.0172 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.01721 to 0.01720, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 111/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0160 - acc: 0.9966 - val_loss: 0.0172 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.01720 to 0.01719, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 112/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0156 - acc: 0.9966 - val_loss: 0.0172 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.01719 to 0.01719, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 113/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0163 - acc: 0.9963 - val_loss: 0.0172 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.01719 to 0.01716, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 114/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0155 - acc: 0.9964 - val_loss: 0.0171 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.01716 to 0.01715, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 115/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0160 - acc: 0.9963 - val_loss: 0.0172 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.01715\n",
      "Epoch 116/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0158 - acc: 0.9966 - val_loss: 0.0171 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.01715 to 0.01711, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 117/200\n",
      "19944/19944 [==============================] - 1s 49us/step - loss: 0.0155 - acc: 0.9967 - val_loss: 0.0171 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.01711 to 0.01710, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 118/200\n",
      "19944/19944 [==============================] - 1s 49us/step - loss: 0.0156 - acc: 0.9965 - val_loss: 0.0171 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.01710 to 0.01710, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 119/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0151 - acc: 0.9967 - val_loss: 0.0171 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.01710 to 0.01710, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 120/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0156 - acc: 0.9966 - val_loss: 0.0171 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.01710 to 0.01708, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 121/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0157 - acc: 0.9966 - val_loss: 0.0171 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.01708\n",
      "Epoch 122/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0155 - acc: 0.9964 - val_loss: 0.0171 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.01708 to 0.01707, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 123/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0156 - acc: 0.9964 - val_loss: 0.0170 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.01707 to 0.01703, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 124/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0153 - acc: 0.9971 - val_loss: 0.0170 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.01703 to 0.01703, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 125/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0150 - acc: 0.9968 - val_loss: 0.0170 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.01703 to 0.01700, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 126/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0148 - acc: 0.9968 - val_loss: 0.0170 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.01700 to 0.01698, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 127/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0148 - acc: 0.9970 - val_loss: 0.0170 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.01698\n",
      "Epoch 128/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0148 - acc: 0.9969 - val_loss: 0.0170 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.01698 to 0.01698, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 129/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0152 - acc: 0.9969 - val_loss: 0.0170 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.01698 to 0.01697, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 130/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0150 - acc: 0.9969 - val_loss: 0.0170 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.01697 to 0.01696, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 131/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0153 - acc: 0.9967 - val_loss: 0.0170 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.01696\n",
      "Epoch 132/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0150 - acc: 0.9969 - val_loss: 0.0170 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.01696\n",
      "Epoch 133/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0153 - acc: 0.9966 - val_loss: 0.0169 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.01696 to 0.01695, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 134/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0152 - acc: 0.9967 - val_loss: 0.0169 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.01695 to 0.01693, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 135/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0150 - acc: 0.9970 - val_loss: 0.0169 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.01693 to 0.01692, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 136/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0146 - acc: 0.9966 - val_loss: 0.0169 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.01692\n",
      "Epoch 137/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0150 - acc: 0.9968 - val_loss: 0.0169 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.01692 to 0.01692, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 138/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0149 - acc: 0.9968 - val_loss: 0.0169 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.01692\n",
      "Epoch 139/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0148 - acc: 0.9969 - val_loss: 0.0169 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.01692 to 0.01691, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 140/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0146 - acc: 0.9968 - val_loss: 0.0169 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.01691 to 0.01691, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 141/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0144 - acc: 0.9969 - val_loss: 0.0169 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.01691 to 0.01690, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 142/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0146 - acc: 0.9968 - val_loss: 0.0169 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.01690\n",
      "Epoch 143/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0140 - acc: 0.9973 - val_loss: 0.0169 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.01690 to 0.01689, saving model to Merge-tuning-2-v1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0146 - acc: 0.9968 - val_loss: 0.0169 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.01689\n",
      "Epoch 145/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0138 - acc: 0.9972 - val_loss: 0.0169 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.01689 to 0.01686, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 146/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0149 - acc: 0.9966 - val_loss: 0.0169 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.01686\n",
      "Epoch 147/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0148 - acc: 0.9966 - val_loss: 0.0168 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.01686 to 0.01685, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 148/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0142 - acc: 0.9969 - val_loss: 0.0168 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.01685 to 0.01683, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 149/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0146 - acc: 0.9971 - val_loss: 0.0168 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.01683 to 0.01683, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 150/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0145 - acc: 0.9969 - val_loss: 0.0168 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.01683\n",
      "Epoch 151/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0147 - acc: 0.9966 - val_loss: 0.0168 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.01683\n",
      "Epoch 152/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0144 - acc: 0.9967 - val_loss: 0.0168 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.01683 to 0.01681, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 153/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0142 - acc: 0.9969 - val_loss: 0.0168 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.01681 to 0.01680, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 154/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0140 - acc: 0.9972 - val_loss: 0.0168 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.01680 to 0.01680, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 155/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0137 - acc: 0.9971 - val_loss: 0.0168 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.01680 to 0.01679, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 156/200\n",
      "19944/19944 [==============================] - 1s 47us/step - loss: 0.0146 - acc: 0.9969 - val_loss: 0.0168 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.01679 to 0.01678, saving model to Merge-tuning-2-v1.h5\n",
      "Epoch 157/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0142 - acc: 0.9970 - val_loss: 0.0168 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.01678\n",
      "Epoch 158/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0143 - acc: 0.9969 - val_loss: 0.0168 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.01678\n",
      "Epoch 159/200\n",
      "19944/19944 [==============================] - 1s 46us/step - loss: 0.0148 - acc: 0.9967 - val_loss: 0.0168 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.01678\n",
      "Epoch 00159: early stopping\n"
     ]
    }
   ],
   "source": [
    "#训练模型并保存在验证集上损失函数最小的权重\n",
    "checkpoint = ModelCheckpoint(model_h5file_base2, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min') #如连续3个epoch,loss都没有没有下降,则停止训练\n",
    "callbacks_list = [stopping,checkpoint]\n",
    "\n",
    "history=model2.fit(X_train, y_train, batch_size=128, epochs=epochs, validation_split=0.2, shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#可视化学习曲线\n",
    "show_learning_curve(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 1s 43us/step\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/dogs-and-cats/helper.py:169: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(index-1, 'label', y_test[i])\n"
     ]
    }
   ],
   "source": [
    "#预测结果   \n",
    "#predict_on_model(X_test, model, model_h5file_base2, pred_file_base2)\n",
    "predict_on_model2(X_test,test_data_dir, 125, model, model_h5file_base2, pred_file_base2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
