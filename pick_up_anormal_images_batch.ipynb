{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.models import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing import *\n",
    "\n",
    "dogs = [\n",
    " 'n02085620','n02085782','n02085936','n02086079'\n",
    ",'n02086240','n02086646','n02086910','n02087046'\n",
    ",'n02087394','n02088094','n02088238','n02088364'\n",
    ",'n02088466','n02088632','n02089078','n02089867'\n",
    ",'n02089973','n02090379','n02090622','n02090721'\n",
    ",'n02091032','n02091134','n02091244','n02091467'\n",
    ",'n02091635','n02091831','n02092002','n02092339'\n",
    ",'n02093256','n02093428','n02093647','n02093754'\n",
    ",'n02093859','n02093991','n02094114','n02094258'\n",
    ",'n02094433','n02095314','n02095570','n02095889'\n",
    ",'n02096051','n02096177','n02096294','n02096437'\n",
    ",'n02096585','n02097047','n02097130','n02097209'\n",
    ",'n02097298','n02097474','n02097658','n02098105'\n",
    ",'n02098286','n02098413','n02099267','n02099429'\n",
    ",'n02099601','n02099712','n02099849','n02100236'\n",
    ",'n02100583','n02100735','n02100877','n02101006'\n",
    ",'n02101388','n02101556','n02102040','n02102177'\n",
    ",'n02102318','n02102480','n02102973','n02104029'\n",
    ",'n02104365','n02105056','n02105162','n02105251'\n",
    ",'n02105412','n02105505','n02105641','n02105855'\n",
    ",'n02106030','n02106166','n02106382','n02106550'\n",
    ",'n02106662','n02107142','n02107312','n02107574'\n",
    ",'n02107683','n02107908','n02108000','n02108089'\n",
    ",'n02108422','n02108551','n02108915','n02109047'\n",
    ",'n02109525','n02109961','n02110063','n02110185'\n",
    ",'n02110341','n02110627','n02110806','n02110958'\n",
    ",'n02111129','n02111277','n02111500','n02111889'\n",
    ",'n02112018','n02112137','n02112350','n02112706'\n",
    ",'n02113023','n02113186','n02113624','n02113712'\n",
    ",'n02113799','n02113978']\n",
    "\n",
    "cats=[\n",
    "'n02123045','n02123159','n02123394','n02123597'\n",
    ",'n02124075','n02125311','n02127052']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全局变量设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_class='cat'   #需要预测的类型,猫和狗分开\n",
    "\n",
    "#windows path\n",
    "#out_path=\"data\\\\anormal\"\n",
    "#ori_path=\"data\\\\test_pick\\\\\"+pick_class  \n",
    "\n",
    "#linux path\n",
    "out_path=\"data/anormal\"\n",
    "ori_path=\"data/test_pick/\"+pick_class  \n",
    "\n",
    "batch_size=22   #共12500张,batch_size=500,则25个bacth\n",
    "top_n=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import *\n",
    "from keras.layers import *\n",
    "import h5py\n",
    "import shutil\n",
    "\n",
    "def pick_not_same(MODEL, image_size, decode_func, lambda_func=None):\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        x = Lambda(lambda_func)(x)   #预处理函数\n",
    "\n",
    "    model = MODEL(input_tensor=x, weights='imagenet', include_top=True)  #含顶部全连接层\n",
    "    \n",
    "    #gen = ImageDataGenerator(rescale = 1./255) #实践证明,预测时不能做rescale\n",
    "    gen = ImageDataGenerator()\n",
    "\n",
    "    test_generator = gen.flow_from_directory(ori_path, image_size, shuffle=False, \n",
    "                                             batch_size=batch_size, class_mode=None)\n",
    "    \n",
    "    # 测试图像的数量\n",
    "    image_numbers = test_generator.samples\n",
    "    print (\"test_generator images numbers={}\".format(image_numbers))\n",
    "    #print(test_generator.filenames)\n",
    "    \n",
    "    # 预测\n",
    "    #test_generator.reset()\n",
    "    y_pred = model.predict_generator(test_generator, test_generator.samples//22, verbose=1)\n",
    "    print(y_pred.shape)\n",
    "    #print(y_pred)\n",
    "    y_pred_n = decode_func(y_pred, top=top_n)\n",
    "    \n",
    "    # 是否同一类别: 在模型预测top_n中有同样的类型，则认为是同一类别\n",
    "    if pick_class == 'cat' :\n",
    "        BAGS=cats   \n",
    "    elif pick_class == 'dog':\n",
    "        BAGS=dogs  \n",
    "    \n",
    "    result = np.zeros(len(y_pred_n))\n",
    "    \n",
    "    for i in range(len(y_pred_n)):   #第i张图片\n",
    "        flag=False\n",
    "        for j in range(len(y_pred_n[i])):   #top_n中的第j个结果 \n",
    "            if y_pred_n[i][j][0] in BAGS:\n",
    "                flag=True\n",
    "                break\n",
    "        if flag:\n",
    "            result[i]=1\n",
    "    \n",
    "    #print (result)\n",
    "    filenames = test_generator.filenames\n",
    "\n",
    "    for i in range(len(result)):\n",
    "        if result[i]==0:\n",
    "            print (filenames[i])\n",
    "            #window path\n",
    "            #out_file=out_path+'\\\\'+filenames[i]\n",
    "            #ori_file=ori_path+'\\\\'+filenames[i]\n",
    "            \n",
    "            #linux path\n",
    "            out_file=out_path+'/'+filenames[i]\n",
    "            ori_file=ori_path+'/'+filenames[i]\n",
    "            print(out_file)\n",
    "            shutil.copy(ori_file, out_file)  #复制判断为不同类的图片\n",
    "            \n",
    "    print(\"{} pick up over\".format(MODEL.__name__))\n",
    "        \n",
    "    return \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 66 images belonging to 1 classes.\n",
      "test_generator images numbers=66\n",
      "3/3 [==============================] - 24s 8s/step\n",
      "(66, 1000)\n",
      "cat/cat.19.jpg\n",
      "data/anormal/cat/cat.19.jpg\n",
      "cat/cat.44.jpg\n",
      "data/anormal/cat/cat.44.jpg\n",
      "cat/cat.45.jpg\n",
      "data/anormal/cat/cat.45.jpg\n",
      "cat/cat.5.jpg\n",
      "data/anormal/cat/cat.5.jpg\n",
      "ResNet50 pick up over\n",
      "Found 66 images belonging to 1 classes.\n",
      "test_generator images numbers=66\n",
      "3/3 [==============================] - 97s 32s/step\n",
      "(66, 1000)\n",
      "InceptionV3 pick up over\n",
      "Found 66 images belonging to 1 classes.\n",
      "test_generator images numbers=66\n",
      "3/3 [==============================] - 85s 28s/step\n",
      "(66, 1000)\n",
      "cat/cat.10.jpg\n",
      "data/anormal/cat/cat.10.jpg\n",
      "cat/cat.12.jpg\n",
      "data/anormal/cat/cat.12.jpg\n",
      "cat/cat.13.jpg\n",
      "data/anormal/cat/cat.13.jpg\n",
      "cat/cat.15.jpg\n",
      "data/anormal/cat/cat.15.jpg\n",
      "cat/cat.16.jpg\n",
      "data/anormal/cat/cat.16.jpg\n",
      "cat/cat.2.jpg\n",
      "data/anormal/cat/cat.2.jpg\n",
      "cat/cat.21.jpg\n",
      "data/anormal/cat/cat.21.jpg\n",
      "cat/cat.24.jpg\n",
      "data/anormal/cat/cat.24.jpg\n",
      "cat/cat.25.jpg\n",
      "data/anormal/cat/cat.25.jpg\n",
      "cat/cat.27.jpg\n",
      "data/anormal/cat/cat.27.jpg\n",
      "cat/cat.28.jpg\n",
      "data/anormal/cat/cat.28.jpg\n",
      "cat/cat.29.jpg\n",
      "data/anormal/cat/cat.29.jpg\n",
      "cat/cat.30.jpg\n",
      "data/anormal/cat/cat.30.jpg\n",
      "cat/cat.31.jpg\n",
      "data/anormal/cat/cat.31.jpg\n",
      "cat/cat.33.jpg\n",
      "data/anormal/cat/cat.33.jpg\n",
      "cat/cat.34.jpg\n",
      "data/anormal/cat/cat.34.jpg\n",
      "cat/cat.35.jpg\n",
      "data/anormal/cat/cat.35.jpg\n",
      "cat/cat.36.jpg\n",
      "data/anormal/cat/cat.36.jpg\n",
      "cat/cat.37.jpg\n",
      "data/anormal/cat/cat.37.jpg\n",
      "cat/cat.38.jpg\n",
      "data/anormal/cat/cat.38.jpg\n",
      "cat/cat.39.jpg\n",
      "data/anormal/cat/cat.39.jpg\n",
      "cat/cat.4.jpg\n",
      "data/anormal/cat/cat.4.jpg\n",
      "cat/cat.40.jpg\n",
      "data/anormal/cat/cat.40.jpg\n",
      "cat/cat.41.jpg\n",
      "data/anormal/cat/cat.41.jpg\n",
      "cat/cat.42.jpg\n",
      "data/anormal/cat/cat.42.jpg\n",
      "cat/cat.43.jpg\n",
      "data/anormal/cat/cat.43.jpg\n",
      "cat/cat.44.jpg\n",
      "data/anormal/cat/cat.44.jpg\n",
      "cat/cat.45.jpg\n",
      "data/anormal/cat/cat.45.jpg\n",
      "cat/cat.46.jpg\n",
      "data/anormal/cat/cat.46.jpg\n",
      "cat/cat.47.jpg\n",
      "data/anormal/cat/cat.47.jpg\n",
      "cat/cat.48.jpg\n",
      "data/anormal/cat/cat.48.jpg\n",
      "cat/cat.49.jpg\n",
      "data/anormal/cat/cat.49.jpg\n",
      "cat/cat.5.jpg\n",
      "data/anormal/cat/cat.5.jpg\n",
      "cat/cat.50.jpg\n",
      "data/anormal/cat/cat.50.jpg\n",
      "cat/cat.51.jpg\n",
      "data/anormal/cat/cat.51.jpg\n",
      "cat/cat.52.jpg\n",
      "data/anormal/cat/cat.52.jpg\n",
      "cat/cat.53.jpg\n",
      "data/anormal/cat/cat.53.jpg\n",
      "cat/cat.54.jpg\n",
      "data/anormal/cat/cat.54.jpg\n",
      "cat/cat.55.jpg\n",
      "data/anormal/cat/cat.55.jpg\n",
      "cat/cat.56.jpg\n",
      "data/anormal/cat/cat.56.jpg\n",
      "cat/cat.57.jpg\n",
      "data/anormal/cat/cat.57.jpg\n",
      "cat/cat.58.jpg\n",
      "data/anormal/cat/cat.58.jpg\n",
      "cat/cat.59.jpg\n",
      "data/anormal/cat/cat.59.jpg\n",
      "cat/cat.6.jpg\n",
      "data/anormal/cat/cat.6.jpg\n",
      "cat/cat.60.jpg\n",
      "data/anormal/cat/cat.60.jpg\n",
      "cat/cat.61.jpg\n",
      "data/anormal/cat/cat.61.jpg\n",
      "cat/cat.62.jpg\n",
      "data/anormal/cat/cat.62.jpg\n",
      "cat/cat.63.jpg\n",
      "data/anormal/cat/cat.63.jpg\n",
      "cat/cat.64.jpg\n",
      "data/anormal/cat/cat.64.jpg\n",
      "cat/cat.65.jpg\n",
      "data/anormal/cat/cat.65.jpg\n",
      "cat/cat.7.jpg\n",
      "data/anormal/cat/cat.7.jpg\n",
      "cat/cat.8.jpg\n",
      "data/anormal/cat/cat.8.jpg\n",
      "cat/cat.9.jpg\n",
      "data/anormal/cat/cat.9.jpg\n",
      "Xception pick up over\n"
     ]
    }
   ],
   "source": [
    "pick_not_same(ResNet50, (224, 224), resnet50.decode_predictions)\n",
    "pick_not_same(InceptionV3, (299, 299), inception_v3.decode_predictions, inception_v3.preprocess_input)\n",
    "pick_not_same(Xception, (299, 299), xception.decode_predictions, xception.preprocess_input)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
