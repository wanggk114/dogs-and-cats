{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.models import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing import *\n",
    "\n",
    "dogs = [\n",
    " 'n02085620','n02085782','n02085936','n02086079'\n",
    ",'n02086240','n02086646','n02086910','n02087046'\n",
    ",'n02087394','n02088094','n02088238','n02088364'\n",
    ",'n02088466','n02088632','n02089078','n02089867'\n",
    ",'n02089973','n02090379','n02090622','n02090721'\n",
    ",'n02091032','n02091134','n02091244','n02091467'\n",
    ",'n02091635','n02091831','n02092002','n02092339'\n",
    ",'n02093256','n02093428','n02093647','n02093754'\n",
    ",'n02093859','n02093991','n02094114','n02094258'\n",
    ",'n02094433','n02095314','n02095570','n02095889'\n",
    ",'n02096051','n02096177','n02096294','n02096437'\n",
    ",'n02096585','n02097047','n02097130','n02097209'\n",
    ",'n02097298','n02097474','n02097658','n02098105'\n",
    ",'n02098286','n02098413','n02099267','n02099429'\n",
    ",'n02099601','n02099712','n02099849','n02100236'\n",
    ",'n02100583','n02100735','n02100877','n02101006'\n",
    ",'n02101388','n02101556','n02102040','n02102177'\n",
    ",'n02102318','n02102480','n02102973','n02104029'\n",
    ",'n02104365','n02105056','n02105162','n02105251'\n",
    ",'n02105412','n02105505','n02105641','n02105855'\n",
    ",'n02106030','n02106166','n02106382','n02106550'\n",
    ",'n02106662','n02107142','n02107312','n02107574'\n",
    ",'n02107683','n02107908','n02108000','n02108089'\n",
    ",'n02108422','n02108551','n02108915','n02109047'\n",
    ",'n02109525','n02109961','n02110063','n02110185'\n",
    ",'n02110341','n02110627','n02110806','n02110958'\n",
    ",'n02111129','n02111277','n02111500','n02111889'\n",
    ",'n02112018','n02112137','n02112350','n02112706'\n",
    ",'n02113023','n02113186','n02113624','n02113712'\n",
    ",'n02113799','n02113978']\n",
    "\n",
    "cats=[\n",
    "'n02123045','n02123159','n02123394','n02123597'\n",
    ",'n02124075','n02125311','n02127052']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全局变量设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_class='cat'   #需要预测的类型,猫和狗分开\n",
    "\n",
    "#windows path\n",
    "#out_path=\"data\\\\anormal\"\n",
    "#ori_path=\"data\\\\test_pick\\\\\"+pick_class  \n",
    "\n",
    "#linux path\n",
    "out_path=\"data/anormal\"\n",
    "ori_path=\"data/test_pick/\"+pick_class  \n",
    "\n",
    "batch_size=125   #共12500张,batch_size=125,则100个bacth\n",
    "top_n=50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import *\n",
    "from keras.layers import *\n",
    "import h5py\n",
    "import shutil\n",
    "\n",
    "def pick_not_same(MODEL, image_size, decode_func, lambda_func=None):\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        x = Lambda(lambda_func)(x)   #预处理函数\n",
    "\n",
    "    model = MODEL(input_tensor=x, weights='imagenet', include_top=True)  #含顶部全连接层\n",
    "    \n",
    "    #gen = ImageDataGenerator(rescale = 1./255) #实践证明,预测时不能做rescale\n",
    "    gen = ImageDataGenerator()\n",
    "\n",
    "    test_generator = gen.flow_from_directory(ori_path, image_size, shuffle=False, \n",
    "                                             batch_size=batch_size, class_mode=None)\n",
    "    \n",
    "    # 测试图像的数量\n",
    "    image_numbers = test_generator.samples\n",
    "    print (\"test_generator images numbers={}\".format(image_numbers))\n",
    "    \n",
    "    # 预测\n",
    "    y_pred = model.predict_generator(test_generator, test_generator.samples//batch_size, verbose=1)\n",
    "    print(y_pred.shape)\n",
    "    y_pred_n = decode_func(y_pred, top=top_n)\n",
    "    \n",
    "    # 是否同一类别: 在模型预测top_n中有同样的类型，则认为是同一类别\n",
    "    if pick_class == 'cat' :\n",
    "        BAGS=cats   \n",
    "    elif pick_class == 'dog':\n",
    "        BAGS=dogs  \n",
    "    \n",
    "    result = np.zeros(len(y_pred_n))\n",
    "    \n",
    "    for i in range(len(y_pred_n)):   #第i张图片\n",
    "        flag=False\n",
    "        for j in range(len(y_pred_n[i])):   #top_n中的第j个结果 \n",
    "            if y_pred_n[i][j][0] in BAGS:\n",
    "                flag=True\n",
    "                break\n",
    "        if flag:\n",
    "            result[i]=1\n",
    "    \n",
    "    filenames = test_generator.filenames\n",
    "\n",
    "    for i in range(len(result)):\n",
    "        if result[i]==0:\n",
    "            print (filenames[i])\n",
    "            #window path\n",
    "            #out_file=out_path+'\\\\'+filenames[i]\n",
    "            #ori_file=ori_path+'\\\\'+filenames[i]\n",
    "            \n",
    "            #linux path\n",
    "            out_file=out_path+'/'+filenames[i]\n",
    "            ori_file=ori_path+'/'+filenames[i]\n",
    "            print(out_file)\n",
    "            shutil.copy(ori_file, out_file)  #复制判断为不同类的图片\n",
    "            \n",
    "    print(\"{} pick up over\".format(MODEL.__name__))\n",
    "        \n",
    "    return \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n",
      "test_generator images numbers=12500\n",
      "100/100 [==============================] - 157s 2s/step\n",
      "(12500, 1000)\n",
      "cat/cat.10029.jpg\n",
      "data/anormal/cat/cat.10029.jpg\n",
      "cat/cat.10700.jpg\n",
      "data/anormal/cat/cat.10700.jpg\n",
      "cat/cat.10712.jpg\n",
      "data/anormal/cat/cat.10712.jpg\n",
      "cat/cat.10946.jpg\n",
      "data/anormal/cat/cat.10946.jpg\n",
      "cat/cat.11184.jpg\n",
      "data/anormal/cat/cat.11184.jpg\n",
      "cat/cat.11222.jpg\n",
      "data/anormal/cat/cat.11222.jpg\n",
      "cat/cat.11231.jpg\n",
      "data/anormal/cat/cat.11231.jpg\n",
      "cat/cat.11565.jpg\n",
      "data/anormal/cat/cat.11565.jpg\n",
      "cat/cat.11607.jpg\n",
      "data/anormal/cat/cat.11607.jpg\n",
      "cat/cat.11777.jpg\n",
      "data/anormal/cat/cat.11777.jpg\n",
      "cat/cat.12227.jpg\n",
      "data/anormal/cat/cat.12227.jpg\n",
      "cat/cat.12272.jpg\n",
      "data/anormal/cat/cat.12272.jpg\n",
      "cat/cat.12378.jpg\n",
      "data/anormal/cat/cat.12378.jpg\n",
      "cat/cat.1485.jpg\n",
      "data/anormal/cat/cat.1485.jpg\n",
      "cat/cat.2337.jpg\n",
      "data/anormal/cat/cat.2337.jpg\n",
      "cat/cat.2433.jpg\n",
      "data/anormal/cat/cat.2433.jpg\n",
      "cat/cat.2457.jpg\n",
      "data/anormal/cat/cat.2457.jpg\n",
      "cat/cat.2509.jpg\n",
      "data/anormal/cat/cat.2509.jpg\n",
      "cat/cat.252.jpg\n",
      "data/anormal/cat/cat.252.jpg\n",
      "cat/cat.2621.jpg\n",
      "data/anormal/cat/cat.2621.jpg\n",
      "cat/cat.2893.jpg\n",
      "data/anormal/cat/cat.2893.jpg\n",
      "cat/cat.2939.jpg\n",
      "data/anormal/cat/cat.2939.jpg\n",
      "cat/cat.3216.jpg\n",
      "data/anormal/cat/cat.3216.jpg\n",
      "cat/cat.335.jpg\n",
      "data/anormal/cat/cat.335.jpg\n",
      "cat/cat.3399.jpg\n",
      "data/anormal/cat/cat.3399.jpg\n",
      "cat/cat.3658.jpg\n",
      "data/anormal/cat/cat.3658.jpg\n",
      "cat/cat.3731.jpg\n",
      "data/anormal/cat/cat.3731.jpg\n",
      "cat/cat.3738.jpg\n",
      "data/anormal/cat/cat.3738.jpg\n",
      "cat/cat.3845.jpg\n",
      "data/anormal/cat/cat.3845.jpg\n",
      "cat/cat.3868.jpg\n",
      "data/anormal/cat/cat.3868.jpg\n",
      "cat/cat.4338.jpg\n",
      "data/anormal/cat/cat.4338.jpg\n",
      "cat/cat.4688.jpg\n",
      "data/anormal/cat/cat.4688.jpg\n",
      "cat/cat.4833.jpg\n",
      "data/anormal/cat/cat.4833.jpg\n",
      "cat/cat.4852.jpg\n",
      "data/anormal/cat/cat.4852.jpg\n",
      "cat/cat.4965.jpg\n",
      "data/anormal/cat/cat.4965.jpg\n",
      "cat/cat.5324.jpg\n",
      "data/anormal/cat/cat.5324.jpg\n",
      "cat/cat.5351.jpg\n",
      "data/anormal/cat/cat.5351.jpg\n",
      "cat/cat.5355.jpg\n",
      "data/anormal/cat/cat.5355.jpg\n",
      "cat/cat.5418.jpg\n",
      "data/anormal/cat/cat.5418.jpg\n",
      "cat/cat.5527.jpg\n",
      "data/anormal/cat/cat.5527.jpg\n",
      "cat/cat.5820.jpg\n",
      "data/anormal/cat/cat.5820.jpg\n",
      "cat/cat.6345.jpg\n",
      "data/anormal/cat/cat.6345.jpg\n",
      "cat/cat.6402.jpg\n",
      "data/anormal/cat/cat.6402.jpg\n",
      "cat/cat.6429.jpg\n",
      "data/anormal/cat/cat.6429.jpg\n",
      "cat/cat.6442.jpg\n",
      "data/anormal/cat/cat.6442.jpg\n",
      "cat/cat.6699.jpg\n",
      "data/anormal/cat/cat.6699.jpg\n",
      "cat/cat.6915.jpg\n",
      "data/anormal/cat/cat.6915.jpg\n",
      "cat/cat.7194.jpg\n",
      "data/anormal/cat/cat.7194.jpg\n",
      "cat/cat.7291.jpg\n",
      "data/anormal/cat/cat.7291.jpg\n",
      "cat/cat.7377.jpg\n",
      "data/anormal/cat/cat.7377.jpg\n",
      "cat/cat.7411.jpg\n",
      "data/anormal/cat/cat.7411.jpg\n",
      "cat/cat.7487.jpg\n",
      "data/anormal/cat/cat.7487.jpg\n",
      "cat/cat.7564.jpg\n",
      "data/anormal/cat/cat.7564.jpg\n",
      "cat/cat.7671.jpg\n",
      "data/anormal/cat/cat.7671.jpg\n",
      "cat/cat.7920.jpg\n",
      "data/anormal/cat/cat.7920.jpg\n",
      "cat/cat.7968.jpg\n",
      "data/anormal/cat/cat.7968.jpg\n",
      "cat/cat.8456.jpg\n",
      "data/anormal/cat/cat.8456.jpg\n",
      "cat/cat.8470.jpg\n",
      "data/anormal/cat/cat.8470.jpg\n",
      "cat/cat.8854.jpg\n",
      "data/anormal/cat/cat.8854.jpg\n",
      "cat/cat.8921.jpg\n",
      "data/anormal/cat/cat.8921.jpg\n",
      "cat/cat.9171.jpg\n",
      "data/anormal/cat/cat.9171.jpg\n",
      "cat/cat.9444.jpg\n",
      "data/anormal/cat/cat.9444.jpg\n",
      "cat/cat.9456.jpg\n",
      "data/anormal/cat/cat.9456.jpg\n",
      "cat/cat.9983.jpg\n",
      "data/anormal/cat/cat.9983.jpg\n",
      "cat/cat.9987.jpg\n",
      "data/anormal/cat/cat.9987.jpg\n",
      "InceptionV3 pick up over\n",
      "Found 12500 images belonging to 1 classes.\n",
      "test_generator images numbers=12500\n",
      "100/100 [==============================] - 285s 3s/step\n",
      "(12500, 1000)\n",
      "cat/cat.10029.jpg\n",
      "data/anormal/cat/cat.10029.jpg\n",
      "cat/cat.10270.jpg\n",
      "data/anormal/cat/cat.10270.jpg\n",
      "cat/cat.10365.jpg\n",
      "data/anormal/cat/cat.10365.jpg\n",
      "cat/cat.10636.jpg\n",
      "data/anormal/cat/cat.10636.jpg\n",
      "cat/cat.10712.jpg\n",
      "data/anormal/cat/cat.10712.jpg\n",
      "cat/cat.11184.jpg\n",
      "data/anormal/cat/cat.11184.jpg\n",
      "cat/cat.11565.jpg\n",
      "data/anormal/cat/cat.11565.jpg\n",
      "cat/cat.12227.jpg\n",
      "data/anormal/cat/cat.12227.jpg\n",
      "cat/cat.12272.jpg\n",
      "data/anormal/cat/cat.12272.jpg\n",
      "cat/cat.12424.jpg\n",
      "data/anormal/cat/cat.12424.jpg\n",
      "cat/cat.12476.jpg\n",
      "data/anormal/cat/cat.12476.jpg\n",
      "cat/cat.12493.jpg\n",
      "data/anormal/cat/cat.12493.jpg\n",
      "cat/cat.2337.jpg\n",
      "data/anormal/cat/cat.2337.jpg\n",
      "cat/cat.2433.jpg\n",
      "data/anormal/cat/cat.2433.jpg\n",
      "cat/cat.2520.jpg\n",
      "data/anormal/cat/cat.2520.jpg\n",
      "cat/cat.2939.jpg\n",
      "data/anormal/cat/cat.2939.jpg\n",
      "cat/cat.3216.jpg\n",
      "data/anormal/cat/cat.3216.jpg\n",
      "cat/cat.3672.jpg\n",
      "data/anormal/cat/cat.3672.jpg\n",
      "cat/cat.372.jpg\n",
      "data/anormal/cat/cat.372.jpg\n",
      "cat/cat.3731.jpg\n",
      "data/anormal/cat/cat.3731.jpg\n",
      "cat/cat.3868.jpg\n",
      "data/anormal/cat/cat.3868.jpg\n",
      "cat/cat.4338.jpg\n",
      "data/anormal/cat/cat.4338.jpg\n",
      "cat/cat.4688.jpg\n",
      "data/anormal/cat/cat.4688.jpg\n",
      "cat/cat.5071.jpg\n",
      "data/anormal/cat/cat.5071.jpg\n",
      "cat/cat.5351.jpg\n",
      "data/anormal/cat/cat.5351.jpg\n",
      "cat/cat.5355.jpg\n",
      "data/anormal/cat/cat.5355.jpg\n",
      "cat/cat.5418.jpg\n",
      "data/anormal/cat/cat.5418.jpg\n",
      "cat/cat.5527.jpg\n",
      "data/anormal/cat/cat.5527.jpg\n",
      "cat/cat.587.jpg\n",
      "data/anormal/cat/cat.587.jpg\n",
      "cat/cat.6429.jpg\n",
      "data/anormal/cat/cat.6429.jpg\n",
      "cat/cat.6442.jpg\n",
      "data/anormal/cat/cat.6442.jpg\n",
      "cat/cat.6655.jpg\n",
      "data/anormal/cat/cat.6655.jpg\n",
      "cat/cat.7377.jpg\n",
      "data/anormal/cat/cat.7377.jpg\n",
      "cat/cat.7487.jpg\n",
      "data/anormal/cat/cat.7487.jpg\n",
      "cat/cat.7564.jpg\n",
      "data/anormal/cat/cat.7564.jpg\n",
      "cat/cat.7703.jpg\n",
      "data/anormal/cat/cat.7703.jpg\n",
      "cat/cat.7920.jpg\n",
      "data/anormal/cat/cat.7920.jpg\n",
      "cat/cat.7968.jpg\n",
      "data/anormal/cat/cat.7968.jpg\n",
      "cat/cat.8087.jpg\n",
      "data/anormal/cat/cat.8087.jpg\n",
      "cat/cat.8456.jpg\n",
      "data/anormal/cat/cat.8456.jpg\n",
      "cat/cat.9090.jpg\n",
      "data/anormal/cat/cat.9090.jpg\n",
      "cat/cat.9171.jpg\n",
      "data/anormal/cat/cat.9171.jpg\n",
      "cat/cat.9444.jpg\n",
      "data/anormal/cat/cat.9444.jpg\n",
      "cat/cat.9494.jpg\n",
      "data/anormal/cat/cat.9494.jpg\n",
      "Xception pick up over\n",
      "Found 12500 images belonging to 1 classes.\n",
      "test_generator images numbers=12500\n",
      "100/100 [==============================] - 339s 3s/step\n",
      "(12500, 1000)\n",
      "cat/cat.10029.jpg\n",
      "data/anormal/cat/cat.10029.jpg\n",
      "cat/cat.10037.jpg\n",
      "data/anormal/cat/cat.10037.jpg\n",
      "cat/cat.10270.jpg\n",
      "data/anormal/cat/cat.10270.jpg\n",
      "cat/cat.10700.jpg\n",
      "data/anormal/cat/cat.10700.jpg\n",
      "cat/cat.10712.jpg\n",
      "data/anormal/cat/cat.10712.jpg\n",
      "cat/cat.11184.jpg\n",
      "data/anormal/cat/cat.11184.jpg\n",
      "cat/cat.12227.jpg\n",
      "data/anormal/cat/cat.12227.jpg\n",
      "cat/cat.12272.jpg\n",
      "data/anormal/cat/cat.12272.jpg\n",
      "cat/cat.12378.jpg\n",
      "data/anormal/cat/cat.12378.jpg\n",
      "cat/cat.2150.jpg\n",
      "data/anormal/cat/cat.2150.jpg\n",
      "cat/cat.2456.jpg\n",
      "data/anormal/cat/cat.2456.jpg\n",
      "cat/cat.2509.jpg\n",
      "data/anormal/cat/cat.2509.jpg\n",
      "cat/cat.2520.jpg\n",
      "data/anormal/cat/cat.2520.jpg\n",
      "cat/cat.2663.jpg\n",
      "data/anormal/cat/cat.2663.jpg\n",
      "cat/cat.2939.jpg\n",
      "data/anormal/cat/cat.2939.jpg\n",
      "cat/cat.3004.jpg\n",
      "data/anormal/cat/cat.3004.jpg\n",
      "cat/cat.3216.jpg\n",
      "data/anormal/cat/cat.3216.jpg\n",
      "cat/cat.335.jpg\n",
      "data/anormal/cat/cat.335.jpg\n",
      "cat/cat.3672.jpg\n",
      "data/anormal/cat/cat.3672.jpg\n",
      "cat/cat.372.jpg\n",
      "data/anormal/cat/cat.372.jpg\n",
      "cat/cat.3731.jpg\n",
      "data/anormal/cat/cat.3731.jpg\n",
      "cat/cat.4126.jpg\n",
      "data/anormal/cat/cat.4126.jpg\n",
      "cat/cat.4308.jpg\n",
      "data/anormal/cat/cat.4308.jpg\n",
      "cat/cat.4338.jpg\n",
      "data/anormal/cat/cat.4338.jpg\n",
      "cat/cat.4503.jpg\n",
      "data/anormal/cat/cat.4503.jpg\n",
      "cat/cat.4575.jpg\n",
      "data/anormal/cat/cat.4575.jpg\n",
      "cat/cat.4688.jpg\n",
      "data/anormal/cat/cat.4688.jpg\n",
      "cat/cat.4965.jpg\n",
      "data/anormal/cat/cat.4965.jpg\n",
      "cat/cat.503.jpg\n",
      "data/anormal/cat/cat.503.jpg\n",
      "cat/cat.5071.jpg\n",
      "data/anormal/cat/cat.5071.jpg\n",
      "cat/cat.5168.jpg\n",
      "data/anormal/cat/cat.5168.jpg\n",
      "cat/cat.5324.jpg\n",
      "data/anormal/cat/cat.5324.jpg\n",
      "cat/cat.5351.jpg\n",
      "data/anormal/cat/cat.5351.jpg\n",
      "cat/cat.5418.jpg\n",
      "data/anormal/cat/cat.5418.jpg\n",
      "cat/cat.5820.jpg\n",
      "data/anormal/cat/cat.5820.jpg\n",
      "cat/cat.6345.jpg\n",
      "data/anormal/cat/cat.6345.jpg\n",
      "cat/cat.6402.jpg\n",
      "data/anormal/cat/cat.6402.jpg\n",
      "cat/cat.6429.jpg\n",
      "data/anormal/cat/cat.6429.jpg\n",
      "cat/cat.6442.jpg\n",
      "data/anormal/cat/cat.6442.jpg\n",
      "cat/cat.6655.jpg\n",
      "data/anormal/cat/cat.6655.jpg\n",
      "cat/cat.6699.jpg\n",
      "data/anormal/cat/cat.6699.jpg\n",
      "cat/cat.7194.jpg\n",
      "data/anormal/cat/cat.7194.jpg\n",
      "cat/cat.7372.jpg\n",
      "data/anormal/cat/cat.7372.jpg\n",
      "cat/cat.7377.jpg\n",
      "data/anormal/cat/cat.7377.jpg\n",
      "cat/cat.7464.jpg\n",
      "data/anormal/cat/cat.7464.jpg\n",
      "cat/cat.7487.jpg\n",
      "data/anormal/cat/cat.7487.jpg\n",
      "cat/cat.7564.jpg\n",
      "data/anormal/cat/cat.7564.jpg\n",
      "cat/cat.7738.jpg\n",
      "data/anormal/cat/cat.7738.jpg\n",
      "cat/cat.7920.jpg\n",
      "data/anormal/cat/cat.7920.jpg\n",
      "cat/cat.7968.jpg\n",
      "data/anormal/cat/cat.7968.jpg\n",
      "cat/cat.8456.jpg\n",
      "data/anormal/cat/cat.8456.jpg\n",
      "cat/cat.8470.jpg\n",
      "data/anormal/cat/cat.8470.jpg\n",
      "cat/cat.9006.jpg\n",
      "data/anormal/cat/cat.9006.jpg\n",
      "cat/cat.9110.jpg\n",
      "data/anormal/cat/cat.9110.jpg\n",
      "cat/cat.9171.jpg\n",
      "data/anormal/cat/cat.9171.jpg\n",
      "cat/cat.9499.jpg\n",
      "data/anormal/cat/cat.9499.jpg\n",
      "cat/cat.9596.jpg\n",
      "data/anormal/cat/cat.9596.jpg\n",
      "InceptionResNetV2 pick up over\n"
     ]
    }
   ],
   "source": [
    "pick_not_same(InceptionV3, (299, 299), inception_v3.decode_predictions, inception_v3.preprocess_input)\n",
    "\n",
    "pick_not_same(Xception, (299, 299), xception.decode_predictions, xception.preprocess_input)\n",
    "\n",
    "pick_not_same(InceptionResNetV2, (299, 299), inception_resnet_v2.decode_predictions, inception_resnet_v2.preprocess_input)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
