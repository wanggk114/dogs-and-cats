{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "In our setup, we:\n",
    "- created a data/ folder\n",
    "- created train/ and validation/ subfolders inside data/\n",
    "- created cats/ and dogs/ subfolders inside train/ and validation/\n",
    "- put the cat pictures index 0-999 in data/train/cats\n",
    "- put the cat pictures index 1000-1400 in data/validation/cats\n",
    "- put the dogs pictures index 12500-13499 in data/train/dogs\n",
    "- put the dog pictures index 13500-13900 in data/validation/dogs\n",
    "So that we have 1000 training examples for each class, and 400 validation examples for each class.\n",
    "In summary, this is our directory structure:\n",
    "```\n",
    "data/\n",
    "    train3/\n",
    "        dog/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cat/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "    validation/\n",
    "        dog/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cat/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "```\n",
    "'''\n",
    "import pandas as pd\n",
    "#from tqdm import tqdm   #进度条\n",
    "from PIL import Image\n",
    "from helper import *\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils import *\n",
    "\n",
    "# path to the model weights files.\n",
    "weights_path = '../keras/examples/vgg16_weights.h5'\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 299, 299\n",
    "\n",
    "train_data_dir = 'data/train3'\n",
    "valid_data_dir = 'data/validation'\n",
    "test_data_dir= 'data/test'\n",
    "\n",
    "nb_train_samples = 19944\n",
    "nb_validation_samples = 4986\n",
    "#batch_size = 277  #19944/277=72  4986/277=18\n",
    "batch_size = 72   #19944/72=277  4986/72=69.25\n",
    "#batch_size = 16   #19944/72=277  4986/72=69.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19944 images belonging to 2 classes.\n",
      "Found 4986 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#构造模型\n",
    "'''\n",
    "x_input = Input((299, 299, 3))\n",
    "x_input = Lambda(xception.preprocess_input)(x_input)\n",
    "\n",
    "base_model = Xception(input_tensor=x_input, weights='imagenet', include_top=False, pooling = 'avg')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "x = Dropout(0.5)(base_model.output)\n",
    "x = Dense(1, activation='sigmoid',kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "model = Model(base_model.input, x)\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "gen = ImageDataGenerator(rotation_range=40,  #旋转数据增强\n",
    "                        width_shift_range=0.2,\n",
    "                        height_shift_range=0.2,\n",
    "                        shear_range=0.2,\n",
    "                        zoom_range=0.2,\n",
    "                        horizontal_flip=True)\n",
    "val_gen = ImageDataGenerator()\n",
    "train_generator = gen.flow_from_directory(train_data_dir, (299, 299), shuffle=True, \n",
    "                                          batch_size=64,class_mode='binary')\n",
    "valid_generator = val_gen.flow_from_directory(valid_data_dir, (299, 299), shuffle=True, \n",
    "                                          batch_size=32,class_mode='binary')\n",
    "\n",
    "for i in range(len(model.layers)):\n",
    "    print(i,model.layers[i].name)\n",
    "'''\n",
    "model,train_generator,valid_generator = build_model(Xception, (img_width, img_height), train_data_dir, valid_data_dir, xception.preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "#训练模型并保存在验证集上损失函数最小的权重\n",
    "filepath=\"xception-best_weight_freeze.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "history=model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples//batch_size,\n",
    "        epochs=10,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=nb_validation_samples//batch_size,\n",
    "        callbacks = callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def predict_on_xception(n, width, heigth, test_data_dir, model, weight, output_name):\n",
    "    x_test = np.zeros((n,width,heigth,3),dtype=np.uint8)\n",
    "\n",
    "    for i in tqdm(range(n)):\n",
    "    #for i in range(n):\n",
    "        img = load_img(test_data_dir+\"/test/\"+'/%d.jpg' % (i+1)) \n",
    "        x_test[i,:,:,:] = img_to_array(img.resize((width,heigth),Image.ANTIALIAS))\n",
    "    \n",
    "#     x_test = xception.preprocess_input(x_test)\n",
    "    model.load_weights(weight)\n",
    "    y_test = model.predict(x_test, verbose=1)\n",
    "    y_test = y_test.clip(min=0.005, max=0.995)\n",
    "    \n",
    "    df = pd.read_csv(\"sample_submission.csv\")\n",
    "    for i in tqdm(range(n)):\n",
    "        df.set_value(i, 'label', y_test[i])\n",
    "    df.to_csv(output_name, index=None)\n",
    "    df.head(10)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 4873/12500 [00:33<00:52, 145.79it/s]"
     ]
    }
   ],
   "source": [
    "predict_on_xception(12500, 299, 299, test_data_dir, model, \"xception-best_weight_freeze.h5\", \"pred-xception-freeze.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_val_sample, _ = next(validation_generator)\n",
    "#y_pred = model.predict(X_val_sample)\n",
    "\n",
    "y_pred = base_model.predict(X_val_sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(X_val_sample))\n",
    "print (y_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
    "\n",
    "nb_sample = 10\n",
    "\n",
    "for x, y in zip(X_val_sample[:nb_sample], y_pred.flatten()[:nb_sample]):\n",
    "    s = pd.Series({'Cat': 1-y, 'Dog': y})\n",
    "    axes = s.plot(kind='bar')\n",
    "    axes.set_xlabel('Class')\n",
    "    axes.set_ylabel('Probability')\n",
    "    axes.set_ylim([0, 1])\n",
    "    plt.show()\n",
    "\n",
    "    img = array_to_img(x)\n",
    "    display(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
